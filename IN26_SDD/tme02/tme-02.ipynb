{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2024-2025\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Semaine 2 : algorithme des k plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double-cliquer ici et insérer les noms et prénoms de votre binôme*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-02</tt> et rajouter à la suite de <tt>tme-02</tt> les noms des membres du binômes séparés par un tiret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation ##\n",
    "\n",
    "Dans ce TME, nous allons mettre en place une \"architecture\" de code nous permettant petit à petit de tester tout au long du semestre différents modèles d'apprentissage supervisé. Dans nos séances, nous allons nous restreindre au cas binaire où les étiquettes des exemples sont $+1$ ou $-1$.\n",
    "\n",
    "\n",
    "### Objectifs de ce TME\n",
    "\n",
    "Le travail à réaliser est le suivant :\n",
    "- continuer à apprendre à (bien) utiliser jupyter notebook\n",
    "- générer aléatoirement des datasets jouets pour expérimenter\n",
    "- se familiariser avec la classe `Classifier` et implémenter un premier classifieur simple\n",
    "- implémenter l'algorithme des $k$ plus proches voisins\n",
    "- réaliser des expérimentations pour étudier les performances de cet algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importations et quelques commandes utiles:\n",
    "\n",
    "Les imports suivants seront généralement nécessaires pour nos séances.\n",
    "\n",
    "Notez que les numéros de version indiqués ne sont pas forcément ceux de votre environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - - - - - - - - - - -\n",
    "# imports utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mtpl\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Les instructions suivantes sont utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - -\n",
    "# Information sur l'environnent utilisé ici:\n",
    "print(\"Version python et des librairies:\")\n",
    "print(\"\\tPython \",sys.version)\n",
    "print(\"\\tpandas: \",pd.__version__)\n",
    "print(\"\\tnumpy: \",np.__version__)\n",
    "print(\"\\tmatplotlib: \",mtpl.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque: pour savoir si une librairie est installée dans votre environnement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy                             1.26.4\n",
      "numpydoc                          1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous souhaitez utiliser une librairie qui n'est pas installé, revoyez le TME 1 qui donne l'instruction d'installation par pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: la commande `grep` n'est pas connue si vous êtes sous Windows, faites simplement : `pip list` et cherchez `numpy` dans le résultat obtenu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques :**\n",
    "Sauf indication contraire, les vecteurs et les matrices seront représentés par des `np.ndarray` numpy que l'on construit par la fonction `np.array()`.\n",
    "\n",
    "La concaténation de vecteurs pour contruire une matrice s'obtient à l'aide de la fonction `np.vstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples :\n",
    "\n",
    "vecteur_1 = np.array([0, 1.5, 4.2])\n",
    "print(\"Type de vecteur_1: \",type(vecteur_1))\n",
    "print(\"vecteur_1 : \",vecteur_1)\n",
    "\n",
    "vecteur_2 = np.array([1.1, 3.8, 20.01])\n",
    "print(\"Type de vecteur_2: \",type(vecteur_2))\n",
    "print(\"vecteur_2 : \",vecteur_2)\n",
    "\n",
    "vecteur_3 = vecteur_1 + vecteur_2\n",
    "print(\"Type de vecteur_3: \",type(vecteur_3))\n",
    "print(\"vecteur_3 : \",vecteur_3)\n",
    "\n",
    "# Exemple d'utilisation de vstack (pour plus de détails, voir la doc numpy sur le web)\n",
    "resultat_1 = np.vstack( (vecteur_1, vecteur_2, vecteur_3) )\n",
    "print(\"Type de matrice_1: \",type(resultat_1))\n",
    "print(\"resultat_1 : \\n\",resultat_1)\n",
    "\n",
    "\n",
    "# On peut aussi utiliser concatenante (pour plus de détails, voir la doc numpy sur le web)\n",
    "resultat_2 = np.concatenate( (vecteur_1, vecteur_2, vecteur_3) )\n",
    "print(\"Type de resultat_2: \",type(resultat_2))\n",
    "print(\"resultat_2 : \\n\",resultat_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1: dataset\n",
    "\n",
    "La première étape consiste à construire un ensemble d'exemples d'apprentissage que l'on appelle par la suite simplement *dataset*. Un dataset est un ensemble de couples $\\{(\\mathbf{x}_1,y_1),...,(\\mathbf{x}_n,y_n)\\}$. \n",
    "\n",
    "Pour nos implémentations, les $\\mathbf{x}_i$ et $y_i$ seront stockés sous la forme de <code>ndarray</code> Numpy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération de données ''Jouet''\n",
    "\n",
    "Nous allons pour l'instant nous intéresser à des datasets \"jouet\" générés selon des distributions choisies à la main.  Ces jeux de données nous permettrons de tester nos algorithmes.\n",
    "\n",
    "Pour pouvoir visualiser nos données, nous allons nous restreindre à des dataset en 2 dimensions pour la description (entrée $\\mathbf{x}_i$ ) et l'étiquette (sortie $y_i$). \n",
    "On aura donc ici: $\\mathbf{x}_i \\in \\mathbb{R}^2$ et $y_i \\in \\{-1;+1\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tirage aléatoire selon une loi uniforme\n",
    "\n",
    "Commençons par un dataset dont les exemples sont générés par un tirage aléatoire selon une loi uniforme.\n",
    "\n",
    "Pour cela, nous utiliserons la fonction numpy `random.uniform`:\n",
    "\n",
    "voir la doc: https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
    "\n",
    "Cette fonction renvoie :\n",
    "- soit un nombre réel obtenu par un tirage aléatoire\n",
    "- soit `ndarray` dont les dimensions ont été précisées et qui contient un ensemble de nombres réels tirés aléatoirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform()  # rend un réel aléatoire de l'intervalle [0.0, 1.0[ (tirage uniforme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-7,5) # rend un réel aléatoire de l'intervalle [-7, 5[ (tirage uniforme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(-7,5,(4,3)) # rend un tableau de 4x3 réels aléatoires pris dans [-7, 5[ (tirage uniforme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour générer aléatoirement les étiquettes (aussi appelées <i>labels</i> ou <i>classes</i>) (qui sont donc des valeurs de {-1, +1}), une contrainte supplémentaire s'ajoute: on souhaite que dans le dataset, il y ait autant d'exemples de chaque classe.\n",
    "\n",
    "Ainsi, si on veut générer un ensemble de 20 labels de telle sorte qu'il y ait exactement 10 valeurs -1 et 10 valeurs +1 dans cet ensemble, la méthode la plus simple est de construire une liste en additionnant une liste de 10 valeurs -1 et une liste de 10 valeurs +1. Pour notre implémentation, cette liste doit ensuite être convertie en `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type : <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lnd = np.array([-1 for i in range(0,10)] + [+1 for i in range(0,10)])\n",
    "print(\"type :\", type(Lnd))\n",
    "Lnd\n",
    "\n",
    "# IMPORTANT POUR LA SUITE : on met les -1 avant les +1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de la mise au point d'un programme qui utilise l'aléatoire, il est important de pouvoir travailler sur des séquences aléatoires qui soient toujours les mêmes.\n",
    "Pour cela, on doit préciser une initialisation de la séquence aléatoire, cela se fait en utilisant la commande numpy `random.seed` qui permet d'initialiser la *graine* du générateur de valeurs aléatoire:\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html\n",
    "\n",
    "Ainsi, avec la même valeur donnée comme graine, on obtiendra toujours la même séquence de tirages aléatoires.\n",
    "\n",
    "Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.50919762,  9.01428613,  4.63987884,  1.97316968, -6.87962719,\n",
       "       -6.88010959, -8.83832776,  7.32352292,  2.02230023,  4.16145156])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "np.random.uniform(-10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on relance pour vérifier que le résultat est identique: \n",
    "np.random.seed(42)\n",
    "np.random.uniform(-10,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> En utilisant la fonction précédente, créer 2 variables :\n",
    "- `data1_desc` : qui est un tableau de 100 exemples de dimension 2 dont les valeurs pour chaque dimension sont tirées aléatoirement dans l'intervalle [-5,5[ \n",
    "- `data1_label` : qui est un tableau d'entiers de {-1,+1}  tel qu'il y ait 50 valeurs -1 suivi de 50 valeurs +1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# ------------------------ Décommenter et compléter les lignes suivantes :\n",
    "# data1_desc = \n",
    "\n",
    "# data1_label = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1_desc) # nombre de lignes de data_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_desc.shape # Dimensions de data_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les 5 premières lignes de data1_desc: \\n\", data1_desc[0:5,:])\n",
    "print(\"Les labels correspondant à ces 5 lignes: \\n\",data1_label[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum des valeurs par colonne:\n",
    "data1_desc.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum des valeurs par colonne:\n",
    "data1_desc.min(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Ecrire la fonction `genere_dataset_uniform` qui prend en argument le nombre de dimensions $d$, **le nombre $n_c$  d'exemples de chaque classe**, ainsi que 2 valeurs pour les bornes inférieure et supérieure des valeurs de description, et qui renvoie un tuple dont le premier composant est un `ndarray` contenant $2*n_c$  vecteurs de description générés aléatoirement en suivant une loi uniforme et le deuxième composant est un `ndarray` contenant les labels correspondant (en respectant l'équirépartition des labels). Les $n_c$ premiers exemples auront le label $-1$, les suivants auront le label $+1$.\n",
    "\n",
    "On fait l'hypothèse que la borne inférieure est plus petite que la borne supérieure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "def genere_dataset_uniform(d, nc, binf=-1, bsup=1):\n",
    "    \"\"\" int * int * float^2 -> tuple[ndarray, ndarray]\n",
    "        Hyp: n est pair\n",
    "        d: nombre de dimensions de la description\n",
    "        nc: nombre d'exemples de chaque classe\n",
    "        les valeurs générées uniformément sont dans [binf,bsup]\n",
    "    \"\"\"\n",
    "    \n",
    "    # #####################\n",
    "    # COMPLETER ICI (et enlever la ligne suivante qui lève une exception)\n",
    "    # #####################\n",
    "    \n",
    "    raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de data2_desc:  (20, 2)\n",
      "Nombre de lignes de data2_lab:  20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Génération d'un dataset de 20 exemples :\n",
    "data2_desc, data2_label = genere_dataset_uniform(2,10,-5,5)\n",
    "\n",
    "print(\"Dimensions de data2_desc: \",data2_desc.shape)\n",
    "print(\"Nombre de lignes de data2_lab: \",len(data2_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les 5 premières lignes de data2_desc: \\n\", data2_desc[0:5,:])\n",
    "print(\"Les labels correspondant à ces 5 lignes: \\n\",data2_label[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** on va utiliser ce dataset `data2` de 20 exemples par la suite pour mettre au point nos fonctions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Un dataset en 2 dimensions peut être affiché en utilisant les fonctions de la librairie `matplotlib` et plus précisément la fonction `pyplot.scatter` permettant de dessiner un nuage de points: \n",
    "\n",
    "https://matplotlib.org/2.0.2/api/pyplot_api.html\n",
    "\n",
    "Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé de l'ensemble des exemples :\n",
    "plt.scatter(data2_desc[:,0],data2_desc[:,1],marker='o',color='red')\n",
    "\n",
    "# Informations d'affichage :\n",
    "plt.title(\"data2\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.grid()  # Grille: à mettre, ou pas\n",
    "\n",
    "# Visualisation du résultat\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remarque : le nom des couleur est standardisé, pour connaître des noms de couleur possible:\n",
    "\n",
    "# ---------------> Décommenter la ligne suivante \n",
    "#mpl.colors.cnames\n",
    "\n",
    "# éventuellement, vous pouvez utiliser internet pour visualiser ces couleurs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est intéressant de  faire un affichage des points qui tient compte de leur étiquette et utiliser des couleurs différentes pour afficher les points. Pour faire cela, il faut commencer par séparer les exemples selon leur étiquette : ceux de label -1 et ceux de label +1. On utilise pour cela la puissance des `ndarray` pour faire des sélections (slices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des exemples de classe -1:\n",
    "data2_negatifs = data2_desc[data2_label == -1]\n",
    "# Extraction des exemples de classe +1:\n",
    "data2_positifs = data2_desc[data2_label == +1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors afficher les points en leur donnant une marque (''marker'') différente (la couleur du marqueur est déterminée automatiquement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé de l'ensemble des exemples :\n",
    "plt.scatter(data2_negatifs[:,0],data2_negatifs[:,1],marker='o', color=\"red\", label='classe -1') # 'o' rouge pour la classe -1\n",
    "plt.scatter(data2_positifs[:,0],data2_positifs[:,1],marker='x', color=\"blue\", label='classe +1') # 'x' bleu pour la classe +1\n",
    "\n",
    "# Informations d'affichage :\n",
    "plt.title(\"data2\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.legend()\n",
    "plt.grid()  # Grille: à mettre, ou pas\n",
    "\n",
    "# Visualisation du résultat\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> En utilisant les instructions précédentes, écrire la fonction `plot2DSet` qui, étant donné deux `ndarray`, un donnant des descriptions et l'autre les labels correspondants, affiche une représentation graphique de ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "def plot2DSet(desc,labels,nom_dataset= \"Dataset\", avec_grid=False):    \n",
    "    \"\"\" ndarray * ndarray * str * bool-> affichage\n",
    "        nom_dataset (str): nom du dataset pour la légende\n",
    "        avec_grid (bool) : True si on veut afficher la grille\n",
    "        la fonction doit utiliser la couleur 'red' pour la classe -1 et 'blue' pour la +1\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################\n",
    "    # COMPLETER ICI (puis enlever la ligne suivante)\n",
    "    #####################################\n",
    "    \n",
    "    raise NotImplementedError(\"Please Implement this method\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si tout est ok, l'appel suivant affiche exactement la même chose que précédemment\n",
    "plot2DSet(data2_desc,data2_label,\"data2\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sans la grille:\n",
    "plot2DSet(data2_desc,data2_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tirage aléatoire selon une loi normale\n",
    "\n",
    "\n",
    "Pour obtenir un dataset plus ''réaliste'', la loi uniforme n'est pas idéale, il est préférable de générer des dataset en utilisant un tirage aléatoire selon une loi normale (ie. représentée par une gaussienne).\n",
    "\n",
    "Pour cela, nous utiliserons la fonction numpy `random.multivariate_normal` :\n",
    "\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.multivariate_normal.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce qui suit, on considère toujours un dataset en 2 dimensions (entrée) et 1 dimension (sortie) comme précédemment.\n",
    "\n",
    "La façon de procéder avec un tel tirage est différente de celle utilisée dans le cas uniforme: \n",
    "- on commence par tirer aléatoirement tous les exemples de la classe -1\n",
    "- puis on tire aléatoirement tous les exemples de la classe +1\n",
    "- on fusionne ces 2 ensembles en les mettant bout à bout\n",
    "- le tableau des labels est donc facile à construire: d'abord les -1 puis les +1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Ecrire la fonction <tt>genere_dataset_gaussian</tt> qui, étant donné 5 arguments:\n",
    "- `positive_center` est le centre de la gaussienne des points positifs (vecteur de taille 2)\n",
    "- `positive_sigma` est la variance de la gaussienne des points positifs (sous forme de matrice 2*2)\n",
    "- `negative_center` est le centre de la gaussienne des points négative (vecteur de taille 2)\n",
    "- `negative_sigma` est la variance de la gaussienne des points négative (sous forme de matrice 2*2)\n",
    "- `nc` est le nombre de points de chaque classe à générer\n",
    "\n",
    "rend un dataset généré aléatoirement en suivant une loi normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "\n",
    "def genere_dataset_gaussian(positive_center, positive_sigma, negative_center, negative_sigma, nc):\n",
    "    \"\"\" les valeurs générées suivent une loi normale\n",
    "        rend un tuple (data_desc, data_labels)\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "    # COMPLETER ICI (puis enlever la ligne suivante)\n",
    "    #####################################\n",
    "    \n",
    "    raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ensuite cette fonction pour générer un nouveau dataset de 100 exemples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation:\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "data_gauss_desc, data_gauss_label = genere_dataset_gaussian(np.array([1,1]),np.array([[1,0],[0,1]]), \\\n",
    "                                                            np.array([-0.5,-1]),np.array([[1,0],[0,1]]), \\\n",
    "                                                            50)\n",
    "\n",
    "print(\"Taille du dataset généré :\", np.shape(data_gauss_desc), \"exemples\")\n",
    "print(\"Rappel: les exemples de labels -1 sont en rouge, ceux de labels +1 sont en bleu.\")\n",
    "\n",
    "# Affichage :\n",
    "plot2DSet(data_gauss_desc, data_gauss_label, \"data_gauss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples dans ce dataset: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'exemples dans ce dataset: \" + str(len(data_gauss_desc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelques exemples et fonctions utiles :\n",
    "np.random.seed(42)\n",
    "v = np.random.uniform(-1,1,2)\n",
    "\n",
    "print(\"Vecteur v: \",v)\n",
    "# Quelques fonctions numpy utiles:\n",
    "\n",
    "# norme euclidienne de v:\n",
    "print(\"Norme euclidienne de v: \",np.linalg.norm(v))\n",
    "\n",
    "v2 = np.array([0.5, 0.5])\n",
    "print(\"Un autre vecteur v2: \",v2,\"\\tet sa norme: \",np.linalg.norm(v2))\n",
    "\n",
    "v3 = v / np.linalg.norm(v)\n",
    "print(\"Un dernier vecteur v3: \",v3,\"\\tet sa norme: \",np.linalg.norm(v3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2: les classifieurs\n",
    "\n",
    "Un classifieur (binaire dans ce cours) permet, pour chaque point d'entrée donné, de calculer un **score** (qui est une valeur de $\\mathbb{R}$) pour déterminer la classe d'un exemple. Cette classe est donnée par le signe de ce score: si le score est strictement négatif, la donnée est associée à la classe (ou label) $-1$, sinon elle est associée à classe (ou label) $+1$. \n",
    "\n",
    "\n",
    "### Représentation orientée objets\n",
    "\n",
    "En LU3IN026, pour implémenter nos algorithmes d'apprentissage, nous allons utiliser quelques éléments de programmation orientée objet (POO) qu'autorise le langage Python. \n",
    "\n",
    "Si vous ne connaissez rien à la POO, il est fortement conseillé de vous familiariser avec elle, par exemple en commençant par lire une documentation ou suivre un tutorial sur le web (par exemple, https://courspython.com/classes-et-objets.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Classifier\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "Les différents classifieurs que l'on va implémenter seront dérivés d'une classe unique : la classe `Classifier` qui est donnée ci-dessous. Pour nous, cette classe est l'équivalent une classe abstraite de Java, elle sera dérivée par héritage pour définir des classifieurs particuliers qui seront vus ce semestre (knn, perceptron, arbres de décision, etc.) et qui devront implémenter toutes les méthodes de cette classe. On aura ainsi un moyen générique d'accéder à nos classifieurs.\n",
    "\n",
    "La classe `Classifier` contient 5 méthodes:\n",
    "- `__init__`: (le constructeur) qui permet d'initialiser les paramètres du classifieur. Les classes filles étendront donc cette méthode en rajoutant les paramètres qui les concernent. Le paramètre obligatoire à donner à la création d'un classifieur est le nombre de dimensions des données qu'il aura à traiter et qui est défini et initialisé dans cette classe (attribut: `self.dimension`).\n",
    "- `train`: c'est la méthode qui permet d'entraîner le modèle, on doit donc donner en argument le dataset qui sert à l'entraînement.\n",
    "- `score`: cette méthode est utilisée une fois le classifieur entrainé. Elle prend en argument la description d'un exemple et elle rend un score (qui est donc une valeur de $\\mathbb{R}$).\n",
    "- `predict`: cette méthode, comme la précédente, s'utilise une fois le classifieur entraîné. Elle rend $\\hat y$, le label (-1 ou +1) qui est prédit par le classifieur pour la description de l'exemple donnée en argument. Généralement, cette valeur de prédiction $\\hat y$ s'obtient à partir du score: si le score est strictement négatif $\\hat y$ vaut  $-1$, sinon il vaut $+1$.\n",
    "- `accuracy`: comme les 2 précédentes, cette méthode s'utilise une fois le classifieur entraîné. Elle permet de calculer la qualité du classifieur qui est mesurée par le **taux de bonne classification** du classifieur sur le dataset donné en argument. C'est une valeur de $[0,1]$ qui s'obtient divisant le nombre d'exemples du dataset qui sont bien classés par le classifieur par le nombre total d'exemples du dataset.\n",
    "\n",
    "Les méthodes `train`, `score` et `predict` dépendent du classifieur que l'on implémente, elle ne seront pas définies dans la classe `Classifier` mais dans les classes qui hériteront ce cette classe.\n",
    "\n",
    "Par contre, la fonction `accuracy` peut être définie dès maintenant dans cette classe `Classifier`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter la classe `Classifier` ci-dessous en donnant l'implémentation de la fonction `accuracy`. Penser à déjà bien examiner les méthodes existantes dans la classe (et que l'on peut utiliser avant qu'elles soient implémentées)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "class Classifier:\n",
    "    \"\"\" Classe (abstraite) pour représenter un classifieur\n",
    "        Attention: cette classe est ne doit pas être instanciée.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dimension):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - intput_dimension (int) : dimension de la description des exemples\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.dimension = input_dimension\n",
    "        \n",
    "    def train(self, desc_set, label_set):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    def score(self,x):\n",
    "        \"\"\" rend le score de prédiction sur x (valeur réelle)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (soit -1 ou soit +1)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def accuracy(self, desc_set, label_set):\n",
    "        \"\"\" Permet de calculer la qualité du système sur un dataset donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"\n",
    "        #####################################\n",
    "        # COMPLETER ICI (puis enlever la ligne suivante)\n",
    "        #####################################\n",
    "        \n",
    "        raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# les $k$-plus proches voisins (*$k$-ppv* ou *$k$-NN*)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Le classifieur des $k$-plus proches voisins (en anglais: $k$-nearest neighbors) est très intuitif: il s'agit de prédire la classe majoritaire dans le voisinage d'un point en examinant ses $k$ plus proches voisins (au sens d'une distance donnée, en général la distance euclidienne).\n",
    "La figure ci-dessous illustre bien le principe général de l'algorithme:\n",
    "\n",
    "<a href=\"https://fr.wikipedia.org/wiki/Méthode_des_k_plus_proches_voisins#/media/Fichier:KnnClassification.svg\"><img src='ressources/Knn.png' width=300px></a>\n",
    "\n",
    "La classe à prédire pour l'exemple représenté par un point vert est celle qui est majoritaire parmi ses $k$ voisins les plus proches.\n",
    "\n",
    "Cet algorithme d'apprentissage est particulier: l'apprentissage consiste simplement à stocker la base d'apprentissage en mémoire (dans un attribut du classifieur donc) pour les réutiliser plus tard.\n",
    "\n",
    "En contrepartie, l'inférence pour faire une prédictiopn coûte très cher: pour chaque prédiction , il faut analyser tout le dataset stocké afin de trouver les $k$ plus proches voisins de l'exemple à prédire.\n",
    "</div>   \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "Description de la classe `ClassifierKNN` (qui étend `Classifier`):\n",
    "- dans le constructeur, on précise, en plus de la dimension du dataset, le nombre de voisins à utiliser (c'est la valeur $k$).\n",
    "- dans la méthode `train`, on donne le dataset qui doit servir de dataset de référence et qui est donc stocké en tant qu'attribut.\n",
    "- dans la méthode `score`, pour une description d'exemple $\\mathbf{x}$ donnée :\n",
    "    - 1) on construit le tableau des distances entre $\\mathbf{x}$ et les exemples du dataset de référence, \n",
    "    - 2) on trie ce tableau grâce, par exemple, à la méthode numpy `argsort`,\n",
    "    - 3) le score qui doit être rendu est calculé à partir de **la proportion d'exemples de classe +1** parmi les $k$ plus proches voisins de $x$. Le score \n",
    "        - vaut $0$ si la proportion est d'exactement $50\\%$ d'exemples de classe +1 parmi les $k$ plus proches voisins;\n",
    "        - est strictement inférieur à $0$ si la proportion est strictement inférieure à $50\\%$. Il est d'autant plus négatif que la proportion est faible;\n",
    "        - est strictement supérieur à $0$ si la proportion est strictement supérieur à $50\\%$. Il est d'autant plus grand que la proportion est importante. <br>\n",
    "    Par exemple, le score peut se calculer à partir de $p \\in [0,1]$, la proportion d'exemples, par $2(p-0.5)$.\n",
    "- dans la méthode `predict`, pour une description d'exemple $\\mathbf{x}$ donnée, on utilise le score rendu par la fonction précédente pour rendre la classe de l'exemple, c'est-à-dire soit $-1$ soit $+1$. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter le code de la classe `ClassifierKNN` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "\n",
    "class ClassifierKNN(Classifier):\n",
    "    \"\"\" Classe pour représenter un classifieur par K plus proches voisins.\n",
    "        Cette classe hérite de la classe Classifier\n",
    "    \"\"\"\n",
    "\n",
    "    # ATTENTION : il faut compléter cette classe avant de l'utiliser !\n",
    "    \n",
    "    def __init__(self, input_dimension, k):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - intput_dimension (int) : dimension d'entrée des exemples\n",
    "                - k (int) : nombre de voisins à considérer\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        Classifier.__init__(self,input_dimension)\n",
    "        ########### A COMPLETER ###################\n",
    "\n",
    "        \n",
    "    def score(self,x):\n",
    "        \"\"\" rend la proportion de +1 parmi les k ppv de x (valeur réelle)\n",
    "            x: une description : un ndarray\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (-1 ou +1)\n",
    "            x: une description : un ndarray\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def train(self, desc_set, label_set):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage en 0.00004 secondes\n",
      "Classification des exemples du dataset:\n",
      "\t-1.255 +4.507 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t+2.320 +0.987 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-3.440 -3.440 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-4.419 +3.662 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t+1.011 +2.081 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-4.794 +4.699 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t+3.324 -2.877 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-3.182 -3.166 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-1.958 +0.248 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t-0.681 -2.088 : -1 ---> classe prédite: -1\t [score = -1.00]\n",
      "\t+1.119 -3.605 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t-2.079 -1.336 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t-0.439 +2.852 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t-3.003 +0.142 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t+0.924 -4.535 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t+1.075 -3.295 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t-4.349 +4.489 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t+4.656 +3.084 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t-1.954 -4.023 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "\t+1.842 -0.598 : +1 ---> classe prédite: +1\t [score = +1.00]\n",
      "Calcul de l'accuracy du dataset (20 exemples) en 0.00033 secondes\n",
      "Taux de bonne classification sur le dataset: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Pour avoir les mêmes valeurs aléatoires :\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Création d'un classifieur KNN de dimension 2 et avec k qui vaut 1:\n",
    "un_KNN = ClassifierKNN(2,1)\n",
    "\n",
    "# Entraînement du classifieur (appel de sa méthode train avec le dataset d'apprentissage)\n",
    "tic = time.time()   # On chronomètre le temps mis pour apprendre\n",
    "un_KNN.train(data2_desc,data2_label)\n",
    "toc = time.time()\n",
    "print(f'Apprentissage en {(toc-tic):1.5f} secondes')\n",
    "\n",
    "# Classification du dataset (contrôle de predict et score):\n",
    "print(\"Classification des exemples du dataset:\")\n",
    "\n",
    "for i in range(0,20):\n",
    "    print(\"\\t{0:+.3f} {1:+.3f} : {2:+} ---> classe prédite: {3:+}\\t [score = {4:+.2f}]\".format(data2_desc[i,:][0], data2_desc[i,:][1], \\\n",
    "                                                                  data2_label[i], \\\n",
    "                                                                  un_KNN.predict(data2_desc[i,:]), \\\n",
    "                                                                  un_KNN.score(data2_desc[i,:])) )\n",
    "\n",
    "# Affichage du taux de bonne classification   \n",
    "tic = time.time() # On chronomètre le temps mis pour calculer l'accuracy sur le dataset\n",
    "val_accuracy = un_KNN.accuracy(data2_desc,data2_label)\n",
    "toc = time.time()\n",
    "\n",
    "print(f'Calcul de l\\'accuracy du dataset ({data2_desc.shape[0]} exemples) en {(toc-tic):1.5f} secondes')\n",
    "\n",
    "print(f'Taux de bonne classification sur le dataset: {val_accuracy:1.3f}')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Calculer la performance (*accuracy*) d'un classifeur KNN qui apprend sur un dataset de 40 exemples générés selon une loi gaussienne et évaluer sa performance sur un autre dataset de test contenant de 1000 autres exemples générés aussi de selon une loi gaussienne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "train_gauss_desc, train_gauss_label = genere_dataset_gaussian( #######  A COMPLETER ####### )\n",
    "\n",
    "test_gauss_desc, test_gauss_label = genere_dataset_gaussian( #######  A COMPLETER ####### )\n",
    "\n",
    "# Affichage :\n",
    "plot2DSet(train_gauss_desc, train_gauss_label, \"train_gauss\")\n",
    "\n",
    "# Création d'un classifieur KNN de dimension 2 et avec k qui vaut 1\n",
    "autre_KNN =  #######  A COMPLETER ####### \n",
    "\n",
    "# Entraînement du classifieur\n",
    "tic = time.time()   \n",
    " #######  A COMPLETER ####### \n",
    "toc = time.time()\n",
    "print(f'Apprentissage en {(toc-tic):1.5f} secondes')\n",
    "\n",
    "# Affichage du taux de bonne classification   \n",
    "tic = time.time() \n",
    "val_accuracy =  #######  A COMPLETER ####### \n",
    "toc = time.time()\n",
    "\n",
    "print(f'Calcul de l\\'accuracy du dataset ({test_gauss_desc.shape[0]} exemples) en {(toc-tic):1.5f} secondes')\n",
    "\n",
    "print(f'Taux de bonne classification sur le dataset test_gauss_desc: {val_accuracy:1.3f}')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tracer la courbe qui donne l'évaluation de l'accuracy obtenue par un classifieur KNN de dimension $k$ entraîné et testé sur les données précédentes, lorsque $k$ varie de 1 à 39.\n",
    "\n",
    "Remarque: ne considérer que les valeurs impaires pour $k$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour mémoriser les accuracies pour chaque k:\n",
    "L_accuracies = []\n",
    "\n",
    "# ##########   COMPLETER\n",
    "\n",
    "# -------------------------------------------------\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation du classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant essayer d'analyser le comportement du classifieur. La première étape consiste à analyser graphiquement la décision par rapport aux données. <BR>\n",
    "**ATTENTION** Ce n'est possible qu'en 2 dimensions\n",
    "\n",
    "\n",
    "Voici une fonction qui permet de dessiner la frontière de décision d'un classifieur. La valeur `step` permet de choisir la précision de tracé du dessin.\n",
    "Le code est entièrement fourni mais pour information, l'idée est la suivante:\n",
    "1. générer une grille de points sur tout l'espace;\n",
    "1. évaluer le classifieur sur toute la grille;\n",
    "1. interpoler un niveau de couleur sur tout l'espace représentant les valeurs du classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frontiere(desc_set, label_set, classifier, step=30):\n",
    "    \"\"\" desc_set * label_set * Classifier * int -> NoneType\n",
    "        Remarque: le 4e argument est optionnel et donne la \"résolution\" du tracé: plus il est important\n",
    "        et plus le tracé de la frontière sera précis.        \n",
    "        Cette fonction affiche la frontière de décision associée au classifieur\n",
    "    \"\"\"\n",
    "    mmax=desc_set.max(0)\n",
    "    mmin=desc_set.min(0)\n",
    "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
    "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "    \n",
    "    # calcul de la prediction pour chaque point de la grille\n",
    "    res=np.array([classifier.predict(grid[i,:]) for i in range(len(grid)) ])\n",
    "    res=res.reshape(x1grid.shape)\n",
    "    # tracer des frontieres\n",
    "    # colors[0] est la couleur des -1 et colors[1] est la couleur des +1\n",
    "    plt.contourf(x1grid,x2grid,res,colors=[\"darksalmon\",\"skyblue\"],levels=[-1000,0,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la frontière de séparation des classes\n",
    "plot_frontiere(data2_desc,data2_label,un_KNN)\n",
    "plot2DSet(data2_desc,data2_label,\"data2\"+\" avec une taille de pas de \"+str(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la frontière de séparation des classes\n",
    "# On met une valeur de \"step\" importante : cela permet un affichage plus précis\n",
    "# Attention : le temps d'exécution sera plus important !\n",
    "plot_frontiere(data2_desc,data2_label,un_KNN,step=200)\n",
    "plot2DSet(data2_desc,data2_label,\"data2\"+\" avec une taille de pas de \"+str(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font>Tracer la frontière de séparation des classes de votre knn `autre_KNN` pour le dataset `data_gauss_desc` avec $k$ égal à 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour avoir les mêmes valeurs aléatoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminée\n",
    "\n",
    "# Affichage de la frontière de séparation des classes\n",
    "plot_frontiere(data_gauss_desc, data_gauss_label,autre_KNN)\n",
    "plot2DSet(data_gauss_desc, data_gauss_label,\"data_gauss avec un knn de k=\"+str(autre_KNN.k))\n",
    "\n",
    "# Performance de ce classifieur:\n",
    "print(\"Accuracy: \",autre_KNN.accuracy(data_gauss_desc, data_gauss_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font>Tracer la frontière de séparation des classes d'un knn entraîné toujours sur le dataset `data_gauss_desc` mais défini en prenant $k$ égal à 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un knn avec k=5 et 2 dimensions pour les données\n",
    "classifierKNN2 = ClassifierKNN(2,5)\n",
    "\n",
    "# Entraînement du classifier:\n",
    "classifierKNN2.train(data_gauss_desc, data_gauss_label)\n",
    "\n",
    "# Affichage de la frontière de séparation des classes\n",
    "plot_frontiere(data_gauss_desc, data_gauss_label,classifierKNN2)\n",
    "plot2DSet(data_gauss_desc, data_gauss_label,\"data_gauss avec un knn de k=\"+str(classifierKNN2.k))\n",
    "\n",
    "# Performance de ce classifieur:\n",
    "print(\"Accuracy: \",classifierKNN2.accuracy(data_gauss_desc, data_gauss_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Etudier les différences qui existent entre la frontière de séparation des classes obtenue avec le kppv k=1 et celle obtenue avec le kppv k=5. Proposer un tracé à la main de la frontière pour différentes valeurs de k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un classifieur linéaire\n",
    "\n",
    "Nous allons maintenant définir un **classifieur linéaire aléatoire** en étendant la classe `Classifier` et en implémentant le constructeur ainsi que les 3 méthodes `predict`, `score` et `train`.\n",
    "\n",
    "Ce classifieur est un des plus simple que l'on puisse construire: on génère aléatoirement une droite (ou hyperplan si on a plus de 2 dimensions) dans l'espace des dimensions en tirant aléatoirement un vecteur $w$ donnant les coefficients de chaque dimensions. L'équation de la droite (hyperplan) est alors donnée par $\\langle x, w\\rangle = 0$ (cf. TD de la semaine 1).\n",
    "\n",
    "Cela nous permis de construire un vecteur de poids. Cette droite est utilisée pour classer les exemples: d'un côté de la droite ils sont prédits de la classe +1, de l'autre côté ils sont prédits de la classe -1.\n",
    "\n",
    "Naturellement, ce classifieur a de bonnes chances de ne pas être très efficace...\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Pour un classifieur linéaire aléatoire:\n",
    "- dans le constructeur, on doit générer aléatoirement un vecteur $w$ de taille `input_dimension` de valeurs dans $[-1,1]$. Les poids doivent ensuite normalisés (c'est-à-dire que la norme de $w$ doit être égale à 1). Ainsi, si $v$ est le vecteur aléatoire à valeurs dans $[-1,1]$ généré, on obtient un vecteur $w$ normalisé à partir de $v$ en prenant chaque composante de $v$ est en la divisant par la norme de $v$.\n",
    "- pour ce classifieur, la méthode `train` ne fait rien. On ne mettra qu'un print permettant d'afficher le message \"Pas d'apprentissage pour ce classifieur\"\n",
    "- pour une description d'exemple $x$, la méthode `score` rend la valeur de $\\langle x, w\\rangle$\n",
    "- pour une description d'exemple $x$, la méthode `predict` doit utiliser la valeur de $\\langle x, w\\rangle$ pour prédire le label (+1 ou -1) associé\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Compléter l'implémentation suivante de la classe <code>ClassifierLineaireRandom</code> qui hérite de `Classifier` et permet de définir un classifieur linéaire aléatoire.\n",
    "\n",
    "Les entrées/sorties sont les bonnes à chaque étape... Mais il n'y a pas d'apprentissage: $w$ est donc aléatoire (mais il doit être à la bonne dimension pour les calculs soient possibles) et déterminé à la création du classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "class ClassifierLineaireRandom(Classifier):\n",
    "    \"\"\" Classe pour représenter un classifieur linéaire aléatoire\n",
    "        Cette classe hérite de la classe Classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dimension):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - intput_dimension (int) : dimension de la description des exemples\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        Classifier.__init__(self,input_dimension)\n",
    "        ########### A COMPLETER ###################\n",
    "        \n",
    "    def train(self, desc_set, label_set):\n",
    "        \"\"\" Permet d'entrainer le modele sur l'ensemble donné\n",
    "            desc_set: ndarray avec des descriptions\n",
    "            label_set: ndarray avec les labels correspondants\n",
    "            Hypothèse: desc_set et label_set ont le même nombre de lignes\n",
    "        \"\"\"        \n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    def score(self,x):\n",
    "        \"\"\" rend le score de prédiction sur x (valeur réelle)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" rend la prediction sur x (soit -1 ou soit +1)\n",
    "            x: une description\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de la classe ainsi créée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour avoir les mêmes valeurs aléatoires :\n",
    "np.random.seed(42)   # supprimer cette ligne une fois la mise au point terminée\n",
    "\n",
    "# Création d'un classifieur linéaire aléatoire de dimension 2:\n",
    "lin_alea = ClassifierLineaireRandom(2)\n",
    "\n",
    "# Par définition, ce classifieur n'a pas besoin d'entraînement\n",
    "lin_alea.train(data1_desc,data1_label)\n",
    "\n",
    "# Classification du dataset (contrôle de predict et score):\n",
    "print(\"Classification du dataset:\")\n",
    "\n",
    "# Affichage du taux de bonne classification    \n",
    "print(\"Taux de bonne classification sur le dataset: \", lin_alea.accuracy(data1_desc,data1_label))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la frontière de séparation des classes\n",
    "plot_frontiere(data_gauss_desc,data_gauss_label,lin_alea,step=100)\n",
    "plot2DSet(data_gauss_desc,data_gauss_label,\"data_gauss avec classifieur linéaire aléatoire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données réelles UCI & USPS\n",
    "\n",
    "Plusieurs datasets sont récupérables directement en python depuis la bibliothèque scikit-learn:\n",
    "https://scikit-learn.org/stable/api/sklearn.datasets.html\n",
    "\n",
    "Il est aussi possible de jouer avec les données USPS (chiffres manuscrits) qui ont été présentées en cours.\n",
    "Dans la suite, nous vous proposons une petite étude sur USPS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Charger les données (le code est fourni) puis isoler les 1 et les 2 pour créer un problème binaire.\n",
    "\n",
    "Pour cette sélection de données en numpy, il peut être intéressant de faire appel à la fonction numpy `where`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('data/usps.pkl', 'rb'))\n",
    "X = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Y = np.array(data['Y_train'], dtype=float)\n",
    "\n",
    "# ------------------------ A COMPLETER :\n",
    "# reduction du jeu de données\n",
    "\n",
    "# X12 = \n",
    "# Y12 =  # encoder en -1/1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Prise en main des données:\n",
    "1. Afficher les dimensions des données. Quel est l'espace de description des données?\n",
    "1. Afficher la première image du jeu de données en utilisant `reshape` et `imshow` comme vu en cours.\n",
    "1. Donner l'histogramme d'illumination du premier pixel (0) puis pour le pixel 219. Analyser le résultat\n",
    "1. Sur le pixel 219, afficher l'histogramme des illuminations pour la classe 1 et pour la classe 2: vous semble-il possible de classer les données sur la base de cette seule information? Quel serait le taux de bonne classification?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Construire un classifieur linéaire aléatoire pour ces données en utilisant le code précédent. Evaluer les performances.\n",
    "\n",
    "Le but de cette question est de vérifier que votre code n'est pas dépendant des dimensions des données: il doit s'adapter aux 256 dimensions des chiffres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Application du classifieur des $k$-plus proches voisins sur `X12` avec $k=7$. Evaluer les performances de votre classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Que se passe-t-il si on construit un knn avec $k=1$? Que va donner le taux de bonne classification? \n",
    "\n",
    "Ce résultat est-il satisfaisant? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le dictionnaire `data` chargé depuis `usps.pkl`, il existe un ensemble d'exemples de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(data['X_test'], dtype=float)\n",
    "Y_test = np.array(data['Y_test'], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour construire `X12` et `Y12`, extraire de ces données les exemples de label 1 et de label 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "# reduction du jeu de données\n",
    "\n",
    "# X12_test = \n",
    "# Y12_test =\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donner l'accuracy d'un classifieur knn avec $k=1$ qui apprend sur les données d'apprentissage (précédentes) et qui est évalué sur ces données test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Que pouvez-vous en conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Proposer une nouvelle version de classifieur $k$-ppv capable de fonctionner pour des problèmes multi-classes, c'est-à-dire quand il existe $C$ classes. Tester les performances de ce nouveau classifieur sur les données USPS.\n",
    "\n",
    "Tenter des modifications sur les données (binarisation, suppression des colonnes de trop forte entropie...) et étudier l'impact sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation : (attention: le temps de calcul peut être long !)\n",
    "\n",
    "class_mc = ClassifierKNN_MC(256,5,10)\n",
    "class_mc.train(X, Y)\n",
    "\n",
    "print(\"KNN avec k=10:\")\n",
    "print(\"Taux de bonne classification sur le dataset: {0:1.5f}\".format(class_mc.accuracy(X_test,Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
